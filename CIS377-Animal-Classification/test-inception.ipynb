{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reworking inceptionV3 loaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50 # type: ignore\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout # type: ignore\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint # type: ignore\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the utility functions\n",
    "from animal_classification import get_data_generators, display_translated_labels\n",
    "\n",
    "# Set the directory path for images\n",
    "directory = r'csv/raw-img'\n",
    "\n",
    "# Define a function for splitting data into train, validation, and test sets\n",
    "def split_data(directory, test_size=0.2, val_size=0.2):\n",
    "    # Get a list of image file paths and their corresponding labels\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_labels = sorted(os.listdir(directory))  # Class labels from folder names\n",
    "    \n",
    "    # Assuming that the directory structure is class_name/image.jpg\n",
    "    for class_label in class_labels:\n",
    "        class_folder = os.path.join(directory, class_label)\n",
    "        for image_name in os.listdir(class_folder):\n",
    "            image_paths.append(os.path.join(class_folder, image_name))\n",
    "            labels.append(class_label)\n",
    "    \n",
    "    # Split into train+val and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(image_paths, labels, test_size=test_size, random_state=42, stratify=labels)\n",
    "    \n",
    "    # Split train+val into separate train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_size / (1 - test_size), random_state=42, stratify=y_train_val)\n",
    "    \n",
    "    return (X_train, X_val, X_test), (y_train, y_val, y_test)\n",
    "\n",
    "\n",
    "# Load data split\n",
    "(X_train, X_val, X_test), (y_train, y_val, y_test) = split_data(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators for training, validation, and test sets\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory, \n",
    "    classes=os.listdir(directory), \n",
    "    class_mode='categorical', \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory, \n",
    "    classes=os.listdir(directory), \n",
    "    class_mode='categorical', \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory, \n",
    "    classes=os.listdir(directory), \n",
    "    class_mode='categorical', \n",
    "    target_size=(224, 224), \n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 (as ResNet18 isn't directly in Keras Applications)\n",
    "base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze the base model's layers\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)  # Replace Flatten with Global Pooling\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)  # Add Dropout for regularization\n",
    "outputs = Dense(len(os.listdir(directory)), activation='softmax')(x)  # Output for the number of classes\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=[\"accuracy\", \"Precision\", \"Recall\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint('resnet50.keras', save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=5,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set after training\n",
    "y_test = test_generator.classes\n",
    "y_pred = np.argmax(model.predict(test_generator), axis=1)\n",
    "print(classification_report(y_test, y_pred, target_names=val_generator.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', xticklabels=val_generator.class_indices, yticklabels=val_generator.class_indices)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, metrics, title=\"Training and Validation Metrics\", save_path=None):\n",
    "    valid_metrics = [metric for metric in metrics if metric in history.history]\n",
    "    num_metrics = len(valid_metrics)\n",
    "    rows = (num_metrics + 1) // 2\n",
    "    fig, axs = plt.subplots(rows, 2, figsize=(14, 5 * rows))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    for ax, metric in zip(axs, valid_metrics):\n",
    "        ax.plot(history.history[metric], label=f'Training {metric.capitalize()}', color='blue', linestyle='-', marker='o')\n",
    "        ax.plot(history.history[f'val_{metric}'], label=f'Validation {metric.capitalize()}', color='orange', linestyle='--', marker='x')\n",
    "        ax.set_xlabel('Epochs')\n",
    "        ax.set_ylabel(metric.capitalize())\n",
    "        ax.set_title(f'Training vs. Validation {metric.capitalize()}')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    for i in range(num_metrics, len(axs)):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "metrics = ['accuracy', 'loss', 'recall', 'precision']\n",
    "plot_training_history(history, metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
